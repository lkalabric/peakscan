print(paste("Working on marker",j,"..."))
# Extract values from marker_info data.frame by marker
ch = markers_info[markers_info$marker == j,]$ch
x_min = markers_info[markers_info$marker == j,]$x_min
x_max = markers_info[markers_info$marker == j,]$x_max
my_panel <- overview2(my.inds=fsa_alldata[[i]], channel=ch, ladder=gs600liz, init.thresh=7000, xlim=c(x_min,x_max))
marker_name = paste0("marker_",i,"_",j)
assign(marker_name, my_painel)
print("Done.")
readline(prompt = "Press [enter] to continue.")
}
}
markers_info
ch
x_min
x_max
# General loop per batch and marker
# =========================================================
for (i in sets_genotyped) {
#markers_set_name = paste0("markers_",i)
#assign(markers_info, subset(my_marker_sets, set == i))
print(paste("Creating panel from markers of",i,"..."))
markers_info <- subset(my_marker_sets, set == i)
for (j in markers_info$marker) {
print(paste("Working on marker",j,"..."))
# Extract values from marker_info data.frame by marker
ch = markers_info[markers_info$marker == j,]$ch
x_min = markers_info[markers_info$marker == j,]$x_min
x_max = markers_info[markers_info$marker == j,]$x_max
my_panel <- overview2(my.inds=fsa_alldata[[i]], channel=ch, ladder=gs600liz, init.thresh=1000, xlim=c(x_min,x_max))
marker_name = paste0("marker_",i,"_",j)
assign(marker_name, my_painel)
print("Done.")
readline(prompt = "Press [enter] to continue.")
}
}
folder <- "~/myfolder"
folder <- "~/GitHub/peakscan/myfolder"
?my.plants
data(my.plants)
my.plants <- my.plants[1:2]
class(my.plants) <- "fsa_stored"
View(my.plants)
plot(my.plants)
plot(my.plants)
plot(my.plants)
plot(my.plants)
plot(my.plants)
my.ladder <- c(50, 75, 100, 125, 129, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375)
ladder.info.attach(stored=my.plants, ladder=my.ladder)
data(my.plants)
my.plants <- my.plants[1:2]
class(my.plants) <- "fsa_stored"
?my.plants
data(my.plants)
my.plants <- my.plants[1:2]
class(my.plants) <- "fsa_stored"
my.ladder <- c(50, 75, 100, 125, 129, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375)
ladder.info.attach(stored=my.plants, ladder=my.ladder)
my.ladder <- c(50, 75, 100, 125, 129, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375)
ladder.info.attach(stored=my.plants, ladder=my.ladder)
knitr::opts_chunk$set(echo = TRUE)
###############################################################################
#                                                                             #
#                Introduction to Fragman peak scoring                         #
#                                                                             #
#   file:///Users/Kathleen/Downloads/fragman_intro_scoring.html               #
#                                                                             #
#    Written in R version 4.1.2 using R Studio RStudio 2022.02.0+443          #
#                                                                             #
#                                                                             #
###############################################################################
# Load required packages
library("Fragman") #1.0.9 - Peak scoring functions
library("tidyr") #1.1.4 - Tidyverse best practices
library("dplyr") #1.0.7 - Tidyverse best practices
library("magrittr") #2.0.1 - Use of L->R piping of functions
library("qpdf") #1.1 - PDF manipulations
#Load JB Additional Scripts
setwd("~/GitHub/P3_Pipeline")
source("check_fsa_v_batch.R") #Data import scripts
source("get_fsa_metadata.R") #Data import scripts
source("storing_inds_rev3.R") #Data import scripts
source("associate_dye_names.R") #Data import scripts
source("score_markers_rev3.R") #Peak scoring scripts
source("Sm_mic_load_v3.R") #Schisto Microsatellite marker sets and expected sizes through Nov 2021
source("transform_scores_df.R") #Wrapper script for many small transformations and name cleanup (derived from J. Long)
#Change the working directory to where the analysis output should be saved
setwd("~/GitHub/P3_Pipeline/peak-analysis") #Same location for github
#Designate the location of the fsa files to be analyzed
fsa_dir <- "~/GitHub/peakscan/fsa" #has to be in its own separate folder
#Import and prepare data for analysis in Fragman package
#Check formats and batch identifiers of all fsa files in target directory
check_fsa_v_batch(fsa_dir) #Summarize file formats and batch identifiers
fsa_info <- get_fsa_metadata(fsa_dir) #Retrieve metadata about fsa files
#Designate the location of the fsa files to be analyzed
fsa_dir <- "~/GitHub/peakscan/fsa_set1" #has to be in its own separate folder
# Load required packages
library("Fragman") #1.0.9 - Peak scoring functions
library("tidyr") #1.1.4 - Tidyverse best practices
library("dplyr") #1.0.7 - Tidyverse best practices
library("magrittr") #2.0.1 - Use of L->R piping of functions
library("qpdf") #1.1 - PDF manipulations
#Load JB Additional Scripts
setwd("~/GitHub/P3_Pipeline")
source("check_fsa_v_batch.R") #Data import scripts
source("get_fsa_metadata.R") #Data import scripts
source("storing_inds_rev3.R") #Data import scripts
source("associate_dye_names.R") #Data import scripts
source("score_markers_rev3.R") #Peak scoring scripts
source("Sm_mic_load_v3.R") #Schisto Microsatellite marker sets and expected sizes through Nov 2021
source("transform_scores_df.R") #Wrapper script for many small transformations and name cleanup (derived from J. Long)
#Change the working directory to where the analysis output should be saved
setwd("~/GitHub/P3_Pipeline/peak-analysis") #Same location for github
#Designate the location of the fsa files to be analyzed
fsa_dir <- "~/GitHub/peakscan/fsa_set1" #has to be in its own separate folder
#Import and prepare data for analysis in Fragman package
#Check formats and batch identifiers of all fsa files in target directory
check_fsa_v_batch(fsa_dir) #Summarize file formats and batch identifiers
fsa_info <- get_fsa_metadata(fsa_dir) #Retrieve metadata about fsa files
head(fsa_info)
write.table(fsa_info, file = paste0("fsa_info.txt"), sep = "\t", quote = FALSE, col.names = TRUE, row.names = FALSE)# Export metadata as tsv to working directory
#Batch import and extract all fsa files into one object
fsa_data <- storing_inds_rev3(fsa_dir, channels = 5, rawPlot = TRUE, fourier = TRUE, saturated = TRUE, lets.pullup = FALSE) #Import files, show plots
#Rename channels with associated dye names
fsa_data <- associate_dye_names(fsa_data, fsa_dir)#Association of dye names using import object and input directory
head(fsa_data[[1]], 5)
#Match the sizing ladder
GS600LIZ <- c(20, 40, 60, 80, 100, 114, 120, 140, 160, 180, 200, 214, 220, 240, 250, 260, 280, 300, 314, 320, 340, 360, 380, 400, 414, 420, 440, 460, 480, 500, 514, 520, 540, 560, 580, 600) #Define vector of internal standard/ladder sizes
ladder.info.attach(stored = fsa_data,ladder = GS600LIZ, ladd.init.thresh = 200, prog = FALSE, draw = TRUE) #Correlate internal ladder with samples
knitr::opts_chunk$set(echo = TRUE)
###############################################################################
#                                                                             #
#                Introduction to Fragman peak scoring                         #
#                                                                             #
#   file:///Users/Kathleen/Downloads/fragman_intro_scoring.html               #
#                                                                             #
#    Written in R version 4.1.2 using R Studio RStudio 2022.02.0+443          #
#                                                                             #
#                                                                             #
###############################################################################
# Load required packages
library("Fragman") #1.0.9 - Peak scoring functions
library("tidyr") #1.1.4 - Tidyverse best practices
library("dplyr") #1.0.7 - Tidyverse best practices
library("magrittr") #2.0.1 - Use of L->R piping of functions
library("qpdf") #1.1 - PDF manipulations
#Load JB Additional Scripts
setwd("~/GitHub/P3_Pipeline")
source("check_fsa_v_batch.R") #Data import scripts
source("get_fsa_metadata.R") #Data import scripts
source("storing_inds_rev3.R") #Data import scripts
source("associate_dye_names.R") #Data import scripts
source("score_markers_rev3.R") #Peak scoring scripts
source("Sm_mic_load_v3.R") #Schisto Microsatellite marker sets and expected sizes through Nov 2021
source("transform_scores_df.R") #Wrapper script for many small transformations and name cleanup (derived from J. Long)
#Change the working directory to where the analysis output should be saved
setwd("~/GitHub/P3_Pipeline/peak-analysis") #Same location for github
#Designate the location of the fsa files to be analyzed
fsa_dir <- "~/GitHub/peakscan/fsa" #has to be in its own separate folder
# Load required packages
library("Fragman") #1.0.9 - Peak scoring functions
library("tidyr") #1.1.4 - Tidyverse best practices
library("dplyr") #1.0.7 - Tidyverse best practices
library("magrittr") #2.0.1 - Use of L->R piping of functions
library("qpdf") #1.1 - PDF manipulations
#Load JB Additional Scripts
setwd("~/GitHub/P3_Pipeline")
source("check_fsa_v_batch.R") #Data import scripts
source("get_fsa_metadata.R") #Data import scripts
source("storing_inds_rev3.R") #Data import scripts
source("associate_dye_names.R") #Data import scripts
source("score_markers_rev3.R") #Peak scoring scripts
source("Sm_mic_load_v3.R") #Schisto Microsatellite marker sets and expected sizes through Nov 2021
source("transform_scores_df.R") #Wrapper script for many small transformations and name cleanup (derived from J. Long)
#Change the working directory to where the analysis output should be saved
setwd("~/GitHub/P3_Pipeline/peak-analysis") #Same location for github
#Designate the location of the fsa files to be analyzed
fsa_dir <- "~/GitHub/peakscan/fsa" #has to be in its own separate folder
#Import and prepare data for analysis in Fragman package
#Check formats and batch identifiers of all fsa files in target directory
check_fsa_v_batch(fsa_dir) #Summarize file formats and batch identifiers
fsa_info <- get_fsa_metadata(fsa_dir) #Retrieve metadata about fsa files
knitr::opts_chunk$set(echo = TRUE) # This a global statment
# Note:
# ===============================================================
# `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the outputs and plots
# General advises:
# ===============================================================
# 1) use "_" instead of "." in variable and function names;
# 2) separate each block of code with a comment and "=====" whenever possible
# 3) this list will continue growing as soon as I learn more about programming in R...
# This piece of code turned out not to be useful since RStudio recognizes missing packages and asks for installation
# ===============================================================
list.of.packages <- c("Fragman","pacman")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
# Loads package Fragman
# ===============================================================
library('Fragman')
# Loads other source codes
# ===============================================================
source("~/GitHub/peakscan/ladders_info.R") # ladders sizes
source("~/GitHub/peakscan/markers_info.R") # microsatellites sets
# General variables
# ===============================================================
threshold=100
my_sets <- unique(my_marker_sets$set)
# It is a good practice to store all fsa files in a different folder. # Read just one folder at a time
#fsa_dir <- "~/GitHub/peakscan/fsa_set1"
#fsa_data <- storing.inds(fsa_dir, channels=5, lets.pullup=FALSE)
# Maybe we should think about saving each set of files in a different folder (i.e. fsa_set1_dir, fsa_set2_dir, etc.)
# ===============================================================
sets_genotyped <- c()
fsa_alldata <- list()
for (i in my_sets) {
fsa_dir <- paste0("~/GitHub/peakscan/fsa_",i)
if (length(list.files(fsa_dir, all.files = TRUE, include.dirs = TRUE, no.. = TRUE)) > 0) {
list.files(fsa_dir, all.files = TRUE, include.dirs = TRUE, no.. = TRUE)
# Reads the fsa files and stores them within a list structure
# ===============================================================
print(i)
fsa_stored <- storing.inds(fsa_dir, channels=5, lets.pullup=FALSE)
# Include here all step of Fragman instead of accumulate to analyze later!
sets_genotyped <- c(sets_genotyped, i)
fsa_alldata <- c(fsa_alldata, list(fsa_stored))
} else {
print(paste("Directory",fsa_dir,"is empty!"))
}
}
names(fsa_alldata) <- sets_genotyped
# Create the list "list.data.covarrubias" indicating the ladder peaks position, height, weigth, correlation and error identified in each file
# ===============================================================
#ladder.info.attach(stored=fsa_data, ladder=gs600liz, ladd.init.thresh=threshold, prog=FALSE, draw=TRUE)
list_data_allcovarrubias <- list()
for (i in sets_genotyped) {
print(paste("Matching ladder from samples of",i,"..."))
ladder.info.attach(stored=fsa_alldata[[i]], ladder=gs600liz, ladd.init.thresh=threshold, prog=FALSE, draw=TRUE)
list_data_allcovarrubias <- c(list_data_allcovarrubias, list(list.data.covarrubias))
}
View(fsa_alldata)
View(fsa_alldata)
View(my_marker_sets)
View(my_marker_sets)
knitr::opts_chunk$set(echo = TRUE)
#Setting the working directory where scripts and data are found and calling the scripts
setwd("~/Documents/GitHub/P3_Pipeline/")
knitr::opts_chunk$set(echo = TRUE)
#Setting the working directory where scripts and data are found and calling the scripts
setwd("~/GitHub/P3_Pipeline/")
source("P3 Data manipulation Combo.R") #Data import scripts
source("JostD_KK.R")
source("Duplicate_check_KK.R")
knitr::opts_chunk$set(echo = TRUE)
inputPanel(
selectInput("n_breaks", label = "Number of bins:",
choices = c(10, 20, 35, 50), selected = 20),
sliderInput("bw_adjust", label = "Bandwidth adjustment:",
min = 0.2, max = 2, value = 1, step = 0.2)
)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
install.packages("remotes")
library("remotes")
install_gitlab("calvinw/ipynbdocument")
install.packages("remotes")
remotes::install_gitlab("calvinw/ipynbdocument")
install.packages("remotes")
knitr::opts_chunk$set(echo = TRUE)
install.packages("remotes")
remotes::install_gitlab("calvinw/ipynbdocument")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
install.packages("remotes")
library("remotes")
install_gitlab("calvinw/ipynbdocument")
install.packages("knitr")
install.packages("rmarkdown")
install.packages("tinytex")
tinytex::install_tinytex()
knitr::opts_chunk$set(echo = TRUE)
install.packages("remotes")
library("remotes")
install_gitlab("calvinw/ipynbdocument")
knitr::opts_chunk$set(echo = TRUE)
install.packages("remotes")
install.packages("remotes")
library(remotes)
install.packages(c("adegenet", "cli", "cluster", "commonmark", "cpp11", "crayon", "curl", "evaluate", "foreign", "isoband", "jsonlite", "lifecycle", "MASS", "Matrix", "nlme", "nnet", "purrr", "qpdf", "readr", "rlang", "rmarkdown", "survival", "tidyselect", "tinytex", "vctrs", "vegan", "vroom"))
install.packages(c("adegenet", "cli", "cluster", "commonmark", "cpp11", "crayon", "curl", "evaluate", "foreign", "isoband", "jsonlite", "lifecycle", "MASS", "Matrix", "nlme", "nnet", "purrr", "qpdf", "readr", "rlang", "rmarkdown", "survival", "tidyselect", "tinytex", "vctrs", "vegan", "vroom"))
install.packages(c("adegenet", "cli", "cluster", "commonmark", "cpp11", "crayon", "curl", "evaluate", "foreign", "isoband", "jsonlite", "lifecycle", "MASS", "Matrix", "nlme", "nnet", "purrr", "qpdf", "readr", "rlang", "rmarkdown", "survival", "tidyselect", "tinytex", "vctrs", "vegan", "vroom"))
install.packages(c("adegenet", "cli", "cluster", "commonmark", "cpp11", "crayon", "curl", "evaluate", "foreign", "isoband", "jsonlite", "lifecycle", "MASS", "Matrix", "nlme", "nnet", "purrr", "qpdf", "readr", "rlang", "rmarkdown", "survival", "tidyselect", "tinytex", "vctrs", "vegan", "vroom"))
install.packages(c("adegenet", "cli", "cluster", "commonmark", "cpp11", "crayon", "curl", "evaluate", "foreign", "isoband", "jsonlite", "lifecycle", "MASS", "Matrix", "nlme", "nnet", "purrr", "qpdf", "readr", "rlang", "rmarkdown", "survival", "tidyselect", "tinytex", "vctrs", "vegan", "vroom"))
install.packages(c("adegenet", "cli", "cluster", "commonmark", "cpp11", "crayon", "curl", "evaluate", "foreign", "isoband", "jsonlite", "lifecycle", "MASS", "Matrix", "nlme", "nnet", "purrr", "qpdf", "readr", "rlang", "rmarkdown", "survival", "tidyselect", "tinytex", "vctrs", "vegan", "vroom"))
install.packages(c("adegenet", "cli", "cluster", "commonmark", "cpp11", "crayon", "curl", "evaluate", "foreign", "isoband", "jsonlite", "lifecycle", "MASS", "Matrix", "nlme", "nnet", "purrr", "qpdf", "readr", "rlang", "rmarkdown", "survival", "tidyselect", "tinytex", "vctrs", "vegan", "vroom"))
install.packages(c("cli", "rlang"))
install.packages(c("cli", "rlang"))
install.packages(c("cli", "rlang"))
install.packages(c("cli", "rlang"))
install.packages(c("cli", "rlang"))
install.packages(c("cli", "rlang"))
knitr::opts_chunk$set(echo = TRUE)
install.packages("knitr")
install.packages("rmarkdown")
knitr::opts_chunk$set(echo = TRUE)
install.packages("reticulate")
install.packages("remotes")
remotes::install_gitlab("calvinw/ipynbdocument")
x<-3
x
knitr::opts_chunk$set(echo = TRUE)
## Installing package ipynbdocument
install.packages("remotes")
remotes::install_gitlab("calvinw/ipynbdocument")
library(remotes)
source("~/GitHub/peakscan/markers_info.R", echo=TRUE)
View(my_marker_sets)
View(my_marker_sets)
View(my_marker_sets)
a <- my_marker_sets
a
---
title: "MS Genotyping pipeline"
# This piece of code turned out not to be useful since RStudio recognizes missing packages and asks for installation
# ===============================================================
list.of.packages <- c("Fragman","pacman")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
# Loads package Fragman
# ===============================================================
library('Fragman')
# Loads other source codes
# ===============================================================
source("~/GitHub/peakscan/ladders_info.R") 		# ladders sizes
source("~/GitHub/peakscan/markers_info.R") 		# microsatellites info & sets (or batches)
source("~/GitHub/peakscan/research_data.R")		# epi & lab data
knitr::opts_chunk$set(echo = TRUE) # This a global statment
# General advises:
# ===============================================================
# 1) use "_" instead of "." in variable and function names;
# 2) separate each block of code with a comment and "=====" whenever possible
# 3) this list will continue growing as soon as I learn more about programming in R...
## MS Genotyping Pipeline
This is an effort to parse microsatellite trace files in fsa format together with epidemiological data to create useful data to be uploaded and analyzed at Online Program SpadeR https://chao.shinyapps.io/SpadeR/.
When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
## Setup
Required packages installation/loading alongside other source codes
```{r setup}
# This piece of code turned out not to be useful since RStudio recognizes missing packages and asks for installation
# ===============================================================
list.of.packages <- c("Fragman","pacman")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
# Loads package Fragman
# ===============================================================
library('Fragman')
# Loads other source codes
# ===============================================================
source("~/GitHub/peakscan/ladders_info.R") 		# ladders sizes
source("~/GitHub/peakscan/markers_info.R") 		# microsatellites info & sets (or batches)
source("~/GitHub/peakscan/research_data.R")		# epi & lab data
# General variables
# ===============================================================
threshold=100
my_sets <- unique(my_marker_sets$set)
# Output data to Streamlit
write.csv(my_sets, "data/my_sets.csv", row.names = FALSE)
# Output data to Streamlit
write.csv(my_sets, "my_sets.csv", row.names = FALSE)
# Output data to Streamlit
write.csv(my_sets, "data/my_sets.csv", row.names = FALSE, col.names = FALSE)
write.csv(my_marker_sets, "data/my_marker_sets.csv", row.names = FALSE, col.names = FALSE)
View(my_marker_sets)
write.csv(my_marker_sets, "data/my_marker_sets.csv", row.names = FALSE)
names(my_sets) <- "set"
# Output data to Streamlit
write.csv(my_sets, "data/my_sets.csv", row.names = FALSE, col.names = FALSE)
my_sets.set
my_sets
my_sets <- unique(my_marker_sets$set)
my_sets
# Output data to Streamlit
write.csv(my_sets, "data/my_sets.csv")
write.csv(my_marker_sets, "data/my_marker_sets.csv")
install.packages(c("cli", "data.table", "digest", "openssl", "rlang", "sys", "xfun", "yaml"))
install.packages(c("cli", "data.table", "digest", "openssl", "rlang", "sys", "xfun", "yaml"))
install.packages(c("cli", "data.table", "digest", "openssl", "rlang", "sys", "xfun", "yaml"))
install.packages(c("cli", "data.table", "digest", "openssl", "rlang", "sys", "xfun", "yaml"))
install.packages(c("cli", "data.table", "digest", "openssl", "rlang", "sys", "xfun", "yaml"))
install.packages(c("cli", "data.table", "digest", "openssl", "rlang", "sys", "xfun", "yaml"))
install.packages(c("cli", "data.table", "digest", "openssl", "rlang", "sys", "xfun", "yaml"))
install.packages(c("cli", "data.table", "digest", "openssl", "rlang", "sys", "xfun", "yaml"))
install.packages(c("cli", "data.table", "digest", "openssl", "rlang", "sys", "xfun", "yaml"))
install.packages(c("cli", "data.table", "digest", "openssl", "rlang", "sys", "xfun", "yaml"))
install.packages(c("cli", "data.table", "digest", "openssl", "rlang", "sys", "xfun", "yaml"))
install.packages("cli")
install.packages("cli")
install.packages("cli")
install.packages("cli")
install.packages("cli")
install.packages("cli")
install.packages("cli")
install.packages("cli")
install.packages("cli")
# channel 1; 6-FAM (blue)
smms2 <- c(211, 215, 219, 223, 227, 231, 235, 239)
smms3 <- c(177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207)
smms3 <- c(177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207)
smms3 <- c(177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207)
my_marker_stes
my_marker_sets
view(my_marker_sets)
# Markers are multiplex for eletrophoresis by sets
# Set or batch 1
set <- "set1"
marker <- (marker= c("smms2", "smms13", "smms16"))
ch <- (ch= c(1, 4, 2))
dye <- (dye = c("FAM", "PET", "VIC"))
x_min <- (x_min= c(219, 171, 201)) # Allele with 1 repeat
x_max <- (x_max= c(295, 228, 258)) # Allele with 20 repeats
set1 <- data.frame(set, marker, ch, dye, x_min, x_max)
# Set or batch 2
set <- "set2"
marker <- (marker= c("smms3", "smms17", "smms18", "smms21"))
ch <- (ch= c(1, 2, 2, 4))
dye <- (dye = c("FAM", "VIC", "VIC", "PET"))
x_min <- (x_min= c(159, 271, 188, 160)) # Allele with 1 repeat
x_max <- (x_max= c(216, 328, 245, 217)) # Allele with 20 repeats
set2 <- data.frame(set, marker, ch, dye, x_min, x_max)
# Set or batch 4
set <- "set4"
marker <- (marker= c("sm13taga", "sm13-410", "sm1f8a", "smda23"))
ch <- (ch= c(1, 4, 2, 3))
dye <- (dye = c("FAM", "PET", "VIC", "NED"))
x_min <- (x_min= c(86, 179, 137, 175)) # Allele with 1 repeat
x_max <- (x_max= c(162, 236, 194, 251)) # Allele with 20 repeats
set4 <- data.frame(set, marker, ch, dye, x_min, x_max)
# Set or batch 5
set <- "set5"
marker <- (marker= c("sm29e6a", "sm13-478", "smu31768", "sm15j15a"))
ch <- (ch= c(1, 1, 3, 2))
dye <- (dye = c("FAM", "FAM", "NED", "VIC"))
x_min <- (x_min= c(150, 209, 179, 193)) # Allele with 1 repeat
x_max <- (x_max= c(207, 266, 236, 250)) # Allele with 20 repeats
set5 <- data.frame(set, marker, ch, dye, x_min, x_max)
# Set or batch 6
set <- "set6"
marker <- (marker= c("lg3_sc36b", "sc23b", "smd28"))
ch <- (ch= c(3, 3, 1))
dye <- (dye = c("NED", "NED", "FAM"))
x_min <- (x_min= c(223, 179, 228)) # Allele with 1 repeat
x_max <- (x_max= c(280, 236, 285)) # Allele with 20 repeats
set6 <- data.frame(set, marker, ch, dye, x_min, x_max)
# Set or batch 7
set <- "set7"
marker <- (marker= c("l46951", "r95529", "lg1_sc276", "lg5_sc475"))
ch <- (ch= c(1, 3, 1, 4))
dye <- (dye = c("FAM", "NED", "FAM", "PET"))
x_min <- (x_min= c(150, 216, 71, 269)) # Allele with 1 repeat
x_max <- (x_max= c(207, 273, 128, 326)) # Allele with 20 repeats
set7 <- data.frame(set, marker, ch, dye, x_min, x_max)
my_marker_sets <- rbind(set1, set2, set4, set5, set6, set7)
# channel 1; 6-FAM (blue)
smms2 <- c(211, 215, 219, 223, 227, 231, 235, 239)
smms3 <- c(177, 180, 183, 186, 189, 192, 195, 198, 201, 204, 207)
sm13taga <- c(102, 106, 110, 114, 118, 122, 126, 130, 134, 138)
sm29e6a <- c(153, 156, 159, 162, 165, 168, 171, 174)
`sm13-478` <- c(224, 227, 230, 233, 236, 239, 242, 245, 248, 251, 254, 257)
smd28 <- c(225, 228, 231, 234, 237, 240)
l46951 <- c(156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189)
lg1_sc276 <- c(98, 101, 104, 107, 110)
ch1_list <- c("smms2", "smms3", "sm13taga", "sm29e6a", "sm13-478", "smd28", "l46951", "lg1_sc276")
# channel 2; VIC (green)
smms16 <- c(210, 213, 216, 219, 222, 225, 228, 231, 234)
smms17 <- c(286, 289, 292, 295, 298, 301, 304, 307)
smms18 <- c(195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231)
sm1f8a <- c(149, 152, 155, 158, 161, 164, 167, 170)
sm15j15a <- c(208, 211, 214, 217, 220, 223, 226, 229, 232)
ch2_list <- c("smms16", "smms17", "smms18", "sm1f8a", "sm15j15a")
# channel 3; NED (yellow)
smda23 <- c(191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235)
smu31768 <- c(185, 188, 191, 194, 197, 200, 203, 206, 209, 212, 215, 218, 221, 224, 227)
lg3_sc36b <- c(232, 235, 238, 241, 244, 247, 250, 253, 256, 259, 262, 265, 268)
sc23b <- c(191, 194, 197, 200, 203, 206, 209, 212, 215, 218)
r95529 <- c(219, 222, 225, 228, 231, 234, 237, 240, 243, 246, 249, 252)
ch3_list <-c("smda23", "smu31768", "lg3_sc36b", "sc23b", "r95529")
# channel 4; PET (red)
smms13 <- c(183, 186, 189, 192, 195, 198, 201, 204)
smms21 <- c(172, 175, 178, 181, 184, 187)
`sm13-410` <- c(191, 194, 197, 200, 203)
lg5_sc475 <- c(281, 284, 287, 290, 293, 296, 299, 302, 305)
ch4_list <- c("smms13", "smms21", "sm13-410", "lg5_sc475")
smms_dye_list <- list(ch1_list, ch2_list, ch3_list, ch4_list)
names(smms_dye_list) <- c("FAM", "VIC", "NED", "PET")
View(my_marker_sets)
View(my_marker_sets)
View(my_marker_sets)
my_marker_sets
# This piece of code turned out not to be useful since RStudio recognizes missing packages and asks for installation
# ===============================================================
list.of.packages <- c("Fragman","pacman")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
# Loads package Fragman
# ===============================================================
library('Fragman')
# Loads other source codes
# ===============================================================
source("~/GitHub/peakscan/ladders_info.R") 		# ladders sizes
source("~/GitHub/peakscan/markers_info.R") 		# microsatellites info & sets (or batches)
source("~/GitHub/peakscan/research_data.R")		# epi & lab data
